{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e64624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from ultralytics import RTDETR\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fba5283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU: NVIDIA GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU) is available and set the device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\") # Use the first GPU\n",
    "    print(f\"Training on GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA not available. Training on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117e5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84450a42",
   "metadata": {},
   "source": [
    "I modified the `rtdetr-shrimp-s.yaml` file to make the model lightweight by reducing its overall complexity and computational requirements. Here's a breakdown of the specific modifications and the reasoning behind them:\n",
    "\n",
    "1. __`scale` parameter modification:__\n",
    "\n",
    "   - __Original:__ `s: [0.33, 0.25, 256]`\n",
    "\n",
    "   - __Modified:__ `s: [0.17, 0.125, 128]`\n",
    "\n",
    "   - __Why:__ The `scale` parameter controls the compound scaling constants for the model, specifically affecting its depth, width, and maximum number of channels.\n",
    "\n",
    "     - Reducing the first value (depth from 0.33 to 0.17) makes the model shallower by decreasing the number of layers or blocks.\n",
    "     - Reducing the second value (width from 0.25 to 0.125) makes the model narrower by decreasing the number of channels in each layer.\n",
    "     - Reducing the third value (max_channels from 256 to 128) sets a lower upper limit on the number of channels.\n",
    "     - These changes collectively reduce the total number of parameters and computational operations, making the model significantly lighter.\n",
    "\n",
    "2. __Channel size reductions in `backbone` and `head` modules:__\n",
    "\n",
    "   - I systematically reduced the channel arguments for various modules throughout the `backbone` and `head` sections. For instance:\n",
    "\n",
    "     - `HGStem, [8, 12]` was changed to `HGStem, [4, 6]`\n",
    "     - `HGBlock, [12, 32, 3]` was changed to `HGBlock, [6, 16, 3]`\n",
    "     - `DWConv, [32, 3, 2, 1, False]` was changed to `DWConv, [16, 3, 2, 1, False]`\n",
    "     - `Conv, [32, 1, 1, None, 1, 1, False]` was changed to `Conv, [16, 1, 1, None, 1, 1, False]`\n",
    "     - `AIFI, [128, 8]` was changed to `AIFI, [64, 8]`\n",
    "     - `RepC3, [32]` was changed to `RepC3, [16]`\n",
    "\n",
    "   - __Why:__ These arguments define the number of input and output channels for the convolutional and block modules. By reducing these channel counts (often by half), the model processes less information at each layer. This significantly decreases the number of floating-point operations (FLOPs) and the memory footprint, resulting in a faster and more resource-efficient model suitable for training in environments with limited computational resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba79ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RTDETR('E:/PD1ModelTrainings/PD1ModelTrainingCodes/rtdetr-shrimp-s.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d421de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.204  Python-3.13.7 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060 SUPER, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=12, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Shrimp-larvae-detection-1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=E:/PD1ModelTrainings/PD1ModelTrainingCodes/rtdetr-shrimp-s.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=train13, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=E:\\PD1ModelTrainings\\PD1ModelTrainingCodes\\runs\\detect\\train13, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1800  ultralytics.nn.modules.block.HGStem          [3, 8, 12]                    \n",
      "  1                  -1  1      2312  ultralytics.nn.modules.block.HGBlock         [12, 12, 32, 3, 1]            \n",
      "  2                  -1  1       352  ultralytics.nn.modules.conv.DWConv           [32, 32, 3, 2, 1, False]      \n",
      "  3                  -1  1     19120  ultralytics.nn.modules.block.HGBlock         [32, 24, 128, 3, 1]           \n",
      "  4                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  5                  -1  1     63600  ultralytics.nn.modules.block.HGBlock         [128, 48, 256, 5, 1, True, False]\n",
      "  6                  -1  1     86128  ultralytics.nn.modules.block.HGBlock         [256, 48, 256, 5, 1, True, True]\n",
      "  7                  -1  1     86128  ultralytics.nn.modules.block.HGBlock         [256, 48, 256, 5, 1, True, True]\n",
      "  8                  -1  1      2816  ultralytics.nn.modules.conv.DWConv           [256, 256, 3, 2, 1, False]    \n",
      "  9                  -1  1    250080  ultralytics.nn.modules.block.HGBlock         [256, 96, 512, 5, 1, True, False]\n",
      " 10                  -1  1     16448  ultralytics.nn.modules.conv.Conv             [512, 32, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1     12704  ultralytics.nn.modules.transformer.AIFI      [32, 128, 8]                  \n",
      " 12                  -1  1      1088  ultralytics.nn.modules.conv.Conv             [32, 32, 1, 1]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1      8256  ultralytics.nn.modules.conv.Conv             [256, 32, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     14592  ultralytics.nn.modules.block.RepC3           [64, 32, 1]                   \n",
      " 17                  -1  1      1088  ultralytics.nn.modules.conv.Conv             [32, 32, 1, 1]                \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1      4160  ultralytics.nn.modules.conv.Conv             [128, 32, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1     14592  ultralytics.nn.modules.block.RepC3           [64, 32, 1]                   \n",
      " 22                  -1  1      9280  ultralytics.nn.modules.conv.Conv             [32, 32, 3, 2]                \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  1     14592  ultralytics.nn.modules.block.RepC3           [64, 32, 1]                   \n",
      " 25                  -1  1      9280  ultralytics.nn.modules.conv.Conv             [32, 32, 3, 2]                \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  1     14592  ultralytics.nn.modules.block.RepC3           [64, 32, 1]                   \n",
      " 28        [21, 24, 27]  1   7131875  ultralytics.nn.modules.head.RTDETRDecoder    [1, [32, 32, 32]]             \n",
      "rtdetr-shrimp-s summary: 289 layers, 7,766,291 parameters, 7,766,291 gradients, 13.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 153.3132.2 MB/s, size: 35.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\PD1ModelTrainings\\PD1ModelTrainingCodes\\Shrimp-larvae-detection-1\\train\\labels.cache... 4140 images, 35 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 4140/4140 6.0Mit/s 0.0s0s\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 4397, len(boxes) = 143573. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.0 ms, read: 63.133.9 MB/s, size: 23.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\PD1ModelTrainings\\PD1ModelTrainingCodes\\Shrimp-larvae-detection-1\\valid\\labels.cache... 386 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 386/386 195.0Kit/s 0.0s\n",
      "WARNING Box and segment counts should be equal, but got len(segments) = 407, len(boxes) = 13790. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "Plotting labels to E:\\PD1ModelTrainings\\PD1ModelTrainingCodes\\runs\\detect\\train13\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 140 weight(decay=0.00046875), 160 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mE:\\PD1ModelTrainings\\PD1ModelTrainingCodes\\runs\\detect\\train13\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       1/60      4.38G      2.063     0.4738     0.5731        495        640: 0% ──────────── 0/345  1.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       1/60      11.4G      1.556     0.3629     0.3614        319        640: 100% ━━━━━━━━━━━━ 345/345 1.3it/s 4:27<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.9it/s 4.3s0.2s\n",
      "                   all        386      13790      0.362      0.609      0.397      0.196\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       2/60      4.49G     0.9248      0.543     0.2577        653        640: 0% ──────────── 0/345  0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       2/60      7.68G     0.9908     0.4788     0.1677        463        640: 100% ━━━━━━━━━━━━ 345/345 0.5it/s 12:08<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.7it/s 4.6s0.3s\n",
      "                   all        386      13790       0.69      0.764      0.695      0.293\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       3/60      4.38G     0.7734     0.4723     0.1035        299        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       3/60        12G     0.8872      0.454     0.1432        573        640: 100% ━━━━━━━━━━━━ 345/345 1.3it/s 4:18<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.2s0.2s\n",
      "                   all        386      13790       0.76      0.797      0.787       0.37\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       4/60      3.97G     0.8004     0.4633     0.1105        289        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       4/60      7.28G      0.795     0.4513     0.1243        525        640: 100% ━━━━━━━━━━━━ 345/345 0.3it/s 16:30<1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.2it/s 4.1s0.2s\n",
      "                   all        386      13790      0.763      0.807       0.78      0.396\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       5/60      4.55G     0.7212     0.4634    0.06843        655        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       5/60      8.98G     0.7595     0.4521     0.1146        477        640: 100% ━━━━━━━━━━━━ 345/345 1.6it/s 3:37<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.1s0.2s\n",
      "                   all        386      13790      0.774       0.83       0.82      0.417\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       6/60      4.61G     0.6819     0.4403     0.0821        708        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       6/60      9.87G     0.7485     0.4527     0.1128        314        640: 100% ━━━━━━━━━━━━ 345/345 1.3it/s 4:21<1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.1s0.2s\n",
      "                   all        386      13790       0.79      0.816      0.824      0.395\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       7/60      4.81G     0.6229     0.4653    0.06466        560        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       7/60      7.54G     0.7006      0.451    0.09874        725        640: 100% ━━━━━━━━━━━━ 345/345 0.3it/s 17:53<2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.1s0.2s\n",
      "                   all        386      13790      0.805      0.834      0.833      0.435\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       8/60       4.5G     0.6676     0.4485    0.07278        601        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       8/60      11.5G     0.6807     0.4509    0.09503        649        640: 100% ━━━━━━━━━━━━ 345/345 1.4it/s 4:03<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.1s0.2s\n",
      "                   all        386      13790      0.817      0.845      0.849      0.433\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K       9/60      5.34G     0.6049      0.445    0.06638        658        640: 0% ──────────── 0/345  0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K       9/60      8.45G     0.6527     0.4497      0.086        269        640: 100% ━━━━━━━━━━━━ 345/345 1.6it/s 3:32<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.1s0.2s\n",
      "                   all        386      13790      0.799      0.836       0.83      0.437\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      10/60      4.82G     0.5509     0.4564    0.05121        685        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      10/60       9.3G     0.6529     0.4508    0.08557        547        640: 100% ━━━━━━━━━━━━ 345/345 1.8it/s 3:16<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.2s0.2s\n",
      "                   all        386      13790      0.799      0.851       0.84      0.458\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      11/60      4.85G     0.5612     0.4435     0.0528        664        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      11/60      8.62G     0.6364     0.4547    0.08237        758        640: 100% ━━━━━━━━━━━━ 345/345 0.3it/s 19:54<3.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.0it/s 4.3s0.3s\n",
      "                   all        386      13790      0.793      0.836      0.823      0.428\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      12/60      5.48G     0.6726     0.4359     0.0765        666        640: 0% ──────────── 0/345  0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      12/60      7.31G     0.6467     0.4531    0.08495        774        640: 100% ━━━━━━━━━━━━ 345/345 1.6it/s 3:32<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.1s0.2s\n",
      "                   all        386      13790      0.814      0.843      0.854      0.456\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      13/60      4.24G     0.5832     0.4554    0.07843        332        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      13/60      7.34G     0.6262     0.4512    0.07992        279        640: 100% ━━━━━━━━━━━━ 345/345 0.4it/s 15:42<1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.7it/s 4.6s0.3s\n",
      "                   all        386      13790      0.825      0.878      0.876      0.466\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      14/60      4.53G      0.611     0.4468    0.07791        453        640: 0% ──────────── 0/345  0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      14/60      11.8G     0.6117     0.4487    0.07876        467        640: 100% ━━━━━━━━━━━━ 345/345 1.3it/s 4:20<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.9it/s 4.3s0.3s\n",
      "                   all        386      13790      0.838      0.876      0.888      0.499\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      15/60      3.97G     0.6112     0.4648    0.07064        337        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      15/60      12.4G     0.6024     0.4507    0.07385        699        640: 100% ━━━━━━━━━━━━ 345/345 1.5it/s 3:47<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.7it/s 4.6s0.3s\n",
      "                   all        386      13790      0.813      0.859      0.858      0.468\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      16/60      4.24G     0.5755     0.4578    0.07548        355        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      16/60      9.38G     0.5938     0.4507    0.07613        599        640: 100% ━━━━━━━━━━━━ 345/345 1.1it/s 5:06<2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.7it/s 4.5s0.3s\n",
      "                   all        386      13790      0.818      0.872      0.871      0.469\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      17/60      4.24G     0.6148     0.4708    0.07907        404        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      17/60      7.93G     0.5827     0.4482    0.07151        534        640: 100% ━━━━━━━━━━━━ 345/345 1.5it/s 3:54<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.8it/s 4.5s0.3s\n",
      "                   all        386      13790      0.837      0.877      0.888      0.478\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      18/60      5.34G     0.6072     0.4328    0.08455        694        640: 0% ──────────── 0/345  0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      18/60      9.59G     0.5848     0.4486     0.0709        652        640: 100% ━━━━━━━━━━━━ 345/345 0.5it/s 11:38<2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.7it/s 4.6s0.3s\n",
      "                   all        386      13790      0.833      0.878      0.882      0.497\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      19/60      4.91G     0.5655     0.4477    0.06549        424        640: 0% ──────────── 0/345  0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      19/60      12.1G     0.5813     0.4508    0.07262        819        640: 100% ━━━━━━━━━━━━ 345/345 1.4it/s 4:02<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.7it/s 4.5s0.3s\n",
      "                   all        386      13790      0.831      0.882       0.89      0.488\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      20/60      4.32G     0.5578     0.4514     0.1173        523        640: 0% ──────────── 0/345  0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      20/60      10.5G     0.5771     0.4484    0.07224        666        640: 100% ━━━━━━━━━━━━ 345/345 0.3it/s 21:12<5.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.0it/s 4.2s0.2s\n",
      "                   all        386      13790      0.834      0.881      0.888      0.497\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      21/60       4.2G      0.645     0.4587    0.07703        342        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      21/60      12.6G     0.5714     0.4477    0.07162        394        640: 100% ━━━━━━━━━━━━ 345/345 1.5it/s 3:44<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.1s0.2s\n",
      "                   all        386      13790       0.83      0.887      0.893      0.503\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      22/60      4.51G      0.657     0.4613    0.08814        368        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      22/60      8.78G     0.5572     0.4468    0.06879        673        640: 100% ━━━━━━━━━━━━ 345/345 0.7it/s 8:32<2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.2it/s 4.1s0.2s\n",
      "                   all        386      13790      0.846      0.893      0.903      0.501\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      23/60      5.11G     0.6202     0.4324    0.07408        611        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      23/60      12.3G     0.5619     0.4496    0.06909        841        640: 100% ━━━━━━━━━━━━ 345/345 1.5it/s 3:48<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.0it/s 4.2s0.2s\n",
      "                   all        386      13790      0.853      0.894      0.906      0.522\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      24/60      3.95G     0.6012     0.4298     0.1026        376        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      24/60      8.58G     0.5449     0.4464    0.06708        296        640: 100% ━━━━━━━━━━━━ 345/345 1.3it/s 4:21<1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.1s0.2s\n",
      "                   all        386      13790      0.854      0.896      0.903      0.517\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      25/60       4.4G     0.5435     0.4467    0.06157        464        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      25/60      7.99G     0.5462      0.443    0.06549        407        640: 100% ━━━━━━━━━━━━ 345/345 0.5it/s 11:04<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.1s0.2s\n",
      "                   all        386      13790      0.838      0.885      0.891       0.52\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      26/60      4.32G     0.4978     0.4523    0.05407        415        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      26/60      7.92G     0.5469     0.4424    0.06594        286        640: 100% ━━━━━━━━━━━━ 345/345 0.2it/s 34:15<2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.0it/s 4.2s0.3s\n",
      "                   all        386      13790      0.854      0.895      0.911      0.519\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      27/60      4.23G     0.5107     0.4464     0.0548        386        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      27/60      9.39G     0.5554     0.4445    0.06806        383        640: 100% ━━━━━━━━━━━━ 345/345 1.4it/s 3:59<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.1s0.2s\n",
      "                   all        386      13790      0.857      0.903      0.911      0.517\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      28/60      3.88G      0.548     0.4658      0.133        308        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      28/60      6.73G     0.5482      0.443    0.06705        313        640: 100% ━━━━━━━━━━━━ 345/345 1.7it/s 3:21<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.2it/s 4.1s0.2s\n",
      "                   all        386      13790      0.854      0.907      0.916      0.523\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      29/60      4.02G       0.48     0.4394    0.04694        374        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      29/60      10.7G     0.5282     0.4406    0.06394        553        640: 100% ━━━━━━━━━━━━ 345/345 1.5it/s 3:56<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.2s0.2s\n",
      "                   all        386      13790      0.857      0.903       0.91      0.532\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      30/60      4.22G     0.5539     0.4403     0.0694        425        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      30/60      7.61G     0.5337     0.4388    0.06406        450        640: 100% ━━━━━━━━━━━━ 345/345 1.3it/s 4:18<2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.2it/s 4.1s0.2s\n",
      "                   all        386      13790      0.851      0.904      0.908      0.536\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      31/60      4.59G     0.4597     0.4207    0.04868        485        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      31/60      9.69G     0.5215     0.4382    0.06235        489        640: 100% ━━━━━━━━━━━━ 345/345 0.7it/s 8:28<6.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.2it/s 4.1s0.2s\n",
      "                   all        386      13790      0.861      0.909      0.919      0.543\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      32/60      5.54G     0.5048     0.4405    0.05784        442        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      32/60      8.56G     0.5204     0.4388    0.06222        572        640: 100% ━━━━━━━━━━━━ 345/345 1.6it/s 3:31<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.2it/s 4.1s0.2s\n",
      "                   all        386      13790      0.856      0.907      0.916      0.495\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      33/60       3.8G     0.4914     0.4557    0.09338        288        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      33/60      12.5G     0.5158     0.4379    0.06291        752        640: 100% ━━━━━━━━━━━━ 345/345 0.1it/s 42:06<10.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.7it/s 4.6s0.3s\n",
      "                   all        386      13790      0.859      0.906      0.913      0.528\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      34/60      3.88G     0.5277     0.4372    0.05416        437        640: 0% ──────────── 0/345  0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      34/60      11.3G      0.515     0.4374     0.0622        582        640: 100% ━━━━━━━━━━━━ 345/345 0.7it/s 8:29<7.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.2it/s 4.1s0.2s\n",
      "                   all        386      13790      0.858      0.897      0.907      0.522\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      35/60      4.59G     0.4419     0.4217    0.04143        624        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      35/60      10.6G     0.5072     0.4378    0.05936        437        640: 100% ━━━━━━━━━━━━ 345/345 1.5it/s 3:50<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.1s0.2s\n",
      "                   all        386      13790      0.866      0.909      0.921       0.56\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      36/60      4.52G     0.4091     0.4299    0.03731        517        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      36/60      9.19G     0.5102     0.4354    0.06248        268        640: 100% ━━━━━━━━━━━━ 345/345 0.6it/s 10:24<3.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.0it/s 4.2s0.3s\n",
      "                   all        386      13790      0.862      0.909       0.92      0.546\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      37/60      4.47G     0.5979     0.4242    0.07332        435        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      37/60      10.1G     0.5064     0.4338    0.05823        458        640: 100% ━━━━━━━━━━━━ 345/345 1.5it/s 3:43<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.1s0.2s\n",
      "                   all        386      13790      0.863      0.913       0.92      0.531\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      38/60      3.98G     0.4875     0.4384    0.06488        382        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      38/60      7.76G     0.5037     0.4356    0.06027        481        640: 100% ━━━━━━━━━━━━ 345/345 1.6it/s 3:41<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 4.1it/s 4.2s0.2s\n",
      "                   all        386      13790      0.868      0.909      0.925      0.527\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      39/60      4.49G     0.4807     0.4258    0.05296        471        640: 0% ──────────── 0/345  0.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      39/60      8.56G     0.5074     0.4352    0.06023        587        640: 100% ━━━━━━━━━━━━ 345/345 0.6it/s 10:17<3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.7it/s 4.6s0.3s\n",
      "                   all        386      13790      0.863      0.912      0.922      0.557\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      40/60      4.69G     0.5616     0.4356     0.0718        593        640: 0% ──────────── 0/345  0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      40/60      9.73G     0.5032      0.433    0.05878        559        640: 100% ━━━━━━━━━━━━ 345/345 1.2it/s 4:44<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.7it/s 4.5s0.3s\n",
      "                   all        386      13790      0.869      0.911      0.927      0.554\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      41/60      4.46G     0.4723     0.4176     0.0471        583        640: 0% ──────────── 0/345  0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      41/60      8.84G     0.4966     0.4328    0.05804        290        640: 100% ━━━━━━━━━━━━ 345/345 1.6it/s 3:31<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.8it/s 4.5s0.3s\n",
      "                   all        386      13790       0.87      0.909      0.927      0.553\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      42/60       4.8G     0.5317      0.433    0.05927        606        640: 0% ──────────── 0/345  0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      42/60      7.56G      0.492     0.4322    0.05815        647        640: 100% ━━━━━━━━━━━━ 345/345 1.2it/s 4:44<0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 17/17 3.7it/s 4.5s0.3s\n",
      "                   all        386      13790       0.87      0.914      0.928      0.557\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n",
      "\u001b[K      43/60      4.59G     0.4667     0.4258    0.04441        580        640: 0% ──────────── 0/345  0.6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PD1ModelTrainings\\DLenv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:97.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      43/60      10.5G     0.4848     0.4296    0.05803        984        640: 34% ━━━━──────── 118/345 1.4it/s 1:22<2:41"
     ]
    }
   ],
   "source": [
    "result = model.train(\n",
    "    data='Shrimp-larvae-detection-1/data.yaml',\n",
    "    epochs = 60,\n",
    "    batch = 12,\n",
    "    device=0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
